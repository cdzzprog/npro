{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from labml_helpers.module import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, layer_norm: bool = False):\n",
    "        super().__init__()\n",
    "        self.hidden_lin = nn.Linear(hidden_size, 4 * hidden_size)\n",
    "        self.input_lin = nn.Linear(input_size, 4 * hidden_size, bias=False)\n",
    "        if layer_norm:\n",
    "            self.layer_norm = nn.ModuleList([nn.LayerNorm(hidden_size) for _ in range(4)])\n",
    "            self.layer_norm_c = nn.LayerNorm(hidden_size)\n",
    "        else:\n",
    "            self.layer_norm = nn.ModuleList([nn.Identity() for _ in range(4)])\n",
    "            self.layer_norm_c = nn.Identity()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, h: torch.Tensor, c: torch.Tensor):\n",
    "        ifgo = self.hidden_lin(h) + self.input_lin(x)\n",
    "        ifgo = ifgo.chunk(4, dim=-1)\n",
    "        ifgo = [self.layer_norm[i](ifgo[i]) for i in range(4)]\n",
    "        i, f, g, o = ifgo\n",
    "        c_next = torch.sigmoid(f) * c + torch.sigmoid(i) * torch.tanh(g)\n",
    "        h_next = torch.sigmoid(o) * torch.tanh(self.layer_norm_c(c_next))\n",
    "        return h_next, c_next\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Module):\n",
    "    \"\"\"\n",
    "    ## Multilayer LSTM\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, n_layers: int):\n",
    "        \"\"\"\n",
    "        Create a network of `n_layers` of LSTM.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # Create cells for each layer. Note that only the first layer gets the input directly.\n",
    "        # Rest of the layers get the input from the layer below\n",
    "        self.cells = nn.ModuleList([LSTMCell(input_size, hidden_size)] +\n",
    "                                   [LSTMCell(hidden_size, hidden_size) for _ in range(n_layers - 1)])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, state: Optional[Tuple[torch.Tensor, torch.Tensor]] = None):\n",
    "        \"\"\"\n",
    "        `x` has shape `[n_steps, batch_size, input_size]` and\n",
    "        `state` is a tuple of $h$ and $c$, each with a shape of `[batch_size, hidden_size]`.\n",
    "        \"\"\"\n",
    "        n_steps, batch_size = x.shape[:2]\n",
    "\n",
    "        # Initialize the state if `None`\n",
    "        if state is None:\n",
    "            h = [x.new_zeros(batch_size, self.hidden_size) for _ in range(self.n_layers)]\n",
    "            c = [x.new_zeros(batch_size, self.hidden_size) for _ in range(self.n_layers)]\n",
    "        else:\n",
    "            (h, c) = state\n",
    "            # Reverse stack the tensors to get the states of each layer\n",
    "            #\n",
    "            # üìù You can just work with the tensor itself but this is easier to debug\n",
    "            h, c = list(torch.unbind(h)), list(torch.unbind(c))\n",
    "\n",
    "        # Array to collect the outputs of the final layer at each time step.\n",
    "        out = []\n",
    "        for t in range(n_steps):\n",
    "            # Input to the first layer is the input itself\n",
    "            inp = x[t]\n",
    "            # Loop through the layers\n",
    "            for layer in range(self.n_layers):\n",
    "                # Get the state of the layer\n",
    "                h[layer], c[layer] = self.cells[layer](inp, h[layer], c[layer])\n",
    "                # Input to the next layer is the state of this layer\n",
    "                inp = h[layer]\n",
    "            # Collect the output $h$ of the final layer\n",
    "            out.append(h[-1])\n",
    "\n",
    "        # Stack the outputs and states\n",
    "        out = torch.stack(out)\n",
    "        h = torch.stack(h)\n",
    "        c = torch.stack(c)\n",
    "\n",
    "        return out, (h, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
